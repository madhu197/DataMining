{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMe5tjQpPgUlAmFtHFCs2xi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhu197/DataMining/blob/main/DL_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhQMGrpi59Rh",
        "outputId": "0ecc3a6e-41b8-48a0-c3eb-879ba57d270f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U tensorflow>=1.8.0\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the fashion-mnist pre-shuffled train data and test data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "print(\"Number of train data - \" + str(len(x_train)))\n",
        "print(\"Number of test data - \" + str(len(x_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp2z4XrC6XzH",
        "outputId": "770d6f19-3fd8-45ca-9b9a-6f7168943850"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train data - 60000\n",
            "Number of test data - 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
        "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
        "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
        "\n",
        "# Reshape input data from (28, 28) to (28, 28, 1)\n",
        "w, h = 28, 28\n",
        "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Print training set shape\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "\n",
        "# Print the number of training, validation, and test datasets\n",
        "print(x_train.shape[0], 'train set')\n",
        "print(x_valid.shape[0], 'validation set')\n",
        "print(x_test.shape[0], 'test set')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvnUaNAv6eWY",
        "outputId": "2aa5e63f-b966-4a3f-bc1c-8bfb255bd639"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n",
            "55000 train set\n",
            "5000 validation set\n",
            "10000 test set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=10,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])\n",
        "\n",
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.best.hdf5')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAs8wlwc6it0",
        "outputId": "829c0f52-e520-420e-817f-442058083364"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 64)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 32)        8224      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 7, 7, 32)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               401664    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 412,778\n",
            "Trainable params: 412,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.5941 - accuracy: 0.7832\n",
            "Epoch 1: val_loss improved from inf to 0.36732, saving model to model.weights.best.hdf5\n",
            "860/860 [==============================] - 20s 11ms/step - loss: 0.5941 - accuracy: 0.7832 - val_loss: 0.3673 - val_accuracy: 0.8734\n",
            "Epoch 2/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.4092 - accuracy: 0.8512\n",
            "Epoch 2: val_loss improved from 0.36732 to 0.32578, saving model to model.weights.best.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.4092 - accuracy: 0.8512 - val_loss: 0.3258 - val_accuracy: 0.8814\n",
            "Epoch 3/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.3655 - accuracy: 0.8673\n",
            "Epoch 3: val_loss improved from 0.32578 to 0.29972, saving model to model.weights.best.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.3656 - accuracy: 0.8673 - val_loss: 0.2997 - val_accuracy: 0.8910\n",
            "Epoch 4/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.3434 - accuracy: 0.8748\n",
            "Epoch 4: val_loss improved from 0.29972 to 0.26990, saving model to model.weights.best.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.3436 - accuracy: 0.8748 - val_loss: 0.2699 - val_accuracy: 0.9052\n",
            "Epoch 5/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.3219 - accuracy: 0.8824\n",
            "Epoch 5: val_loss improved from 0.26990 to 0.25369, saving model to model.weights.best.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.3221 - accuracy: 0.8823 - val_loss: 0.2537 - val_accuracy: 0.9094\n",
            "Epoch 6/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.3043 - accuracy: 0.8887\n",
            "Epoch 6: val_loss improved from 0.25369 to 0.25153, saving model to model.weights.best.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3042 - accuracy: 0.8888 - val_loss: 0.2515 - val_accuracy: 0.9072\n",
            "Epoch 7/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.2932 - accuracy: 0.8922\n",
            "Epoch 7: val_loss improved from 0.25153 to 0.24274, saving model to model.weights.best.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.2935 - accuracy: 0.8922 - val_loss: 0.2427 - val_accuracy: 0.9122\n",
            "Epoch 8/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.2800 - accuracy: 0.8963\n",
            "Epoch 8: val_loss improved from 0.24274 to 0.23702, saving model to model.weights.best.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.2798 - accuracy: 0.8964 - val_loss: 0.2370 - val_accuracy: 0.9112\n",
            "Epoch 9/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.9000\n",
            "Epoch 9: val_loss improved from 0.23702 to 0.22681, saving model to model.weights.best.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.2731 - accuracy: 0.9000 - val_loss: 0.2268 - val_accuracy: 0.9148\n",
            "Epoch 10/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.2640 - accuracy: 0.9024\n",
            "Epoch 10: val_loss improved from 0.22681 to 0.21985, saving model to model.weights.best.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2640 - accuracy: 0.9024 - val_loss: 0.2198 - val_accuracy: 0.9166\n",
            "\n",
            " Test accuracy: 0.9079999923706055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.filter1.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=10,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])\n",
        "\n",
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.filter1.hdf5')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOjIfQna8Mnp",
        "outputId": "ea23296b-2f01-4b40-e45f-87cec5338b11"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 32)        160       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 14, 14, 16)        2064      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 7, 7, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 7, 7, 16)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               200960    \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 205,754\n",
            "Trainable params: 205,754\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.6607 - accuracy: 0.7579\n",
            "Epoch 1: val_loss improved from inf to 0.40990, saving model to model.weights.filter1.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.6603 - accuracy: 0.7581 - val_loss: 0.4099 - val_accuracy: 0.8608\n",
            "Epoch 2/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.4600 - accuracy: 0.8334\n",
            "Epoch 2: val_loss improved from 0.40990 to 0.35300, saving model to model.weights.filter1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.4600 - accuracy: 0.8334 - val_loss: 0.3530 - val_accuracy: 0.8740\n",
            "Epoch 3/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.4102 - accuracy: 0.8511\n",
            "Epoch 3: val_loss improved from 0.35300 to 0.32488, saving model to model.weights.filter1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.4101 - accuracy: 0.8511 - val_loss: 0.3249 - val_accuracy: 0.8866\n",
            "Epoch 4/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8606\n",
            "Epoch 4: val_loss improved from 0.32488 to 0.30162, saving model to model.weights.filter1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3828 - accuracy: 0.8607 - val_loss: 0.3016 - val_accuracy: 0.8904\n",
            "Epoch 5/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.3631 - accuracy: 0.8667\n",
            "Epoch 5: val_loss improved from 0.30162 to 0.28219, saving model to model.weights.filter1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3634 - accuracy: 0.8666 - val_loss: 0.2822 - val_accuracy: 0.8978\n",
            "Epoch 6/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.3513 - accuracy: 0.8710\n",
            "Epoch 6: val_loss improved from 0.28219 to 0.27852, saving model to model.weights.filter1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3509 - accuracy: 0.8712 - val_loss: 0.2785 - val_accuracy: 0.8982\n",
            "Epoch 7/10\n",
            "853/860 [============================>.] - ETA: 0s - loss: 0.3344 - accuracy: 0.8767\n",
            "Epoch 7: val_loss improved from 0.27852 to 0.26085, saving model to model.weights.filter1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3345 - accuracy: 0.8768 - val_loss: 0.2608 - val_accuracy: 0.9030\n",
            "Epoch 8/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.3265 - accuracy: 0.8786\n",
            "Epoch 8: val_loss improved from 0.26085 to 0.25718, saving model to model.weights.filter1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3267 - accuracy: 0.8785 - val_loss: 0.2572 - val_accuracy: 0.9054\n",
            "Epoch 9/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.3181 - accuracy: 0.8826\n",
            "Epoch 9: val_loss did not improve from 0.25718\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3181 - accuracy: 0.8826 - val_loss: 0.2636 - val_accuracy: 0.9022\n",
            "Epoch 10/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.8834\n",
            "Epoch 10: val_loss improved from 0.25718 to 0.24646, saving model to model.weights.filter1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3140 - accuracy: 0.8834 - val_loss: 0.2465 - val_accuracy: 0.9120\n",
            "\n",
            " Test accuracy: 0.9010000228881836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.filter2.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=10,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])\n",
        "\n",
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.filter2.hdf5')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoWqyvA5-ans",
        "outputId": "5fb35303-8b79-4ee3-c0c1-b2a11d8eab29"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 64)        320       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 14, 14, 64)        16448     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               803072    \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 822,410\n",
            "Trainable params: 822,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.5687 - accuracy: 0.7925\n",
            "Epoch 1: val_loss improved from inf to 0.35385, saving model to model.weights.filter2.hdf5\n",
            "860/860 [==============================] - 10s 11ms/step - loss: 0.5687 - accuracy: 0.7925 - val_loss: 0.3538 - val_accuracy: 0.8766\n",
            "Epoch 2/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8612\n",
            "Epoch 2: val_loss improved from 0.35385 to 0.31005, saving model to model.weights.filter2.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.3876 - accuracy: 0.8612 - val_loss: 0.3101 - val_accuracy: 0.8892\n",
            "Epoch 3/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.3458 - accuracy: 0.8739\n",
            "Epoch 3: val_loss improved from 0.31005 to 0.28326, saving model to model.weights.filter2.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.3457 - accuracy: 0.8739 - val_loss: 0.2833 - val_accuracy: 0.8968\n",
            "Epoch 4/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.3192 - accuracy: 0.8830\n",
            "Epoch 4: val_loss improved from 0.28326 to 0.27294, saving model to model.weights.filter2.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.3192 - accuracy: 0.8830 - val_loss: 0.2729 - val_accuracy: 0.8964\n",
            "Epoch 5/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.3015 - accuracy: 0.8900\n",
            "Epoch 5: val_loss improved from 0.27294 to 0.25282, saving model to model.weights.filter2.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.3013 - accuracy: 0.8900 - val_loss: 0.2528 - val_accuracy: 0.9098\n",
            "Epoch 6/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2831 - accuracy: 0.8958\n",
            "Epoch 6: val_loss did not improve from 0.25282\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.2829 - accuracy: 0.8959 - val_loss: 0.2696 - val_accuracy: 0.9014\n",
            "Epoch 7/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.2671 - accuracy: 0.9009\n",
            "Epoch 7: val_loss improved from 0.25282 to 0.23696, saving model to model.weights.filter2.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.2671 - accuracy: 0.9009 - val_loss: 0.2370 - val_accuracy: 0.9088\n",
            "Epoch 8/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.2604 - accuracy: 0.9038\n",
            "Epoch 8: val_loss improved from 0.23696 to 0.22194, saving model to model.weights.filter2.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.2602 - accuracy: 0.9039 - val_loss: 0.2219 - val_accuracy: 0.9184\n",
            "Epoch 9/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2524 - accuracy: 0.9075\n",
            "Epoch 9: val_loss did not improve from 0.22194\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.2523 - accuracy: 0.9075 - val_loss: 0.2233 - val_accuracy: 0.9168\n",
            "Epoch 10/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.2456 - accuracy: 0.9091\n",
            "Epoch 10: val_loss improved from 0.22194 to 0.21206, saving model to model.weights.filter2.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.2455 - accuracy: 0.9091 - val_loss: 0.2121 - val_accuracy: 0.9206\n",
            "\n",
            " Test accuracy: 0.9157000184059143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=5, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.kernel1.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=10,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])\n",
        "\n",
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.kernel1.hdf5')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rgqKeKX_MoO",
        "outputId": "45eb4376-285e-43e4-8349-3ac5283c35f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 14, 14, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 7, 7, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 7, 7, 32)          0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 256)               401664    \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 424,362\n",
            "Trainable params: 424,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.5736 - accuracy: 0.7919\n",
            "Epoch 1: val_loss improved from inf to 0.35173, saving model to model.weights.kernel1.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.5736 - accuracy: 0.7919 - val_loss: 0.3517 - val_accuracy: 0.8722\n",
            "Epoch 2/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.8619\n",
            "Epoch 2: val_loss improved from 0.35173 to 0.31246, saving model to model.weights.kernel1.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3812 - accuracy: 0.8619 - val_loss: 0.3125 - val_accuracy: 0.8848\n",
            "Epoch 3/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.3355 - accuracy: 0.8772\n",
            "Epoch 3: val_loss improved from 0.31246 to 0.27197, saving model to model.weights.kernel1.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3355 - accuracy: 0.8772 - val_loss: 0.2720 - val_accuracy: 0.8994\n",
            "Epoch 4/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.3107 - accuracy: 0.8843\n",
            "Epoch 4: val_loss improved from 0.27197 to 0.25327, saving model to model.weights.kernel1.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3106 - accuracy: 0.8844 - val_loss: 0.2533 - val_accuracy: 0.9072\n",
            "Epoch 5/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.2951 - accuracy: 0.8918\n",
            "Epoch 5: val_loss improved from 0.25327 to 0.24180, saving model to model.weights.kernel1.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.2949 - accuracy: 0.8919 - val_loss: 0.2418 - val_accuracy: 0.9114\n",
            "Epoch 6/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.2776 - accuracy: 0.8964\n",
            "Epoch 6: val_loss improved from 0.24180 to 0.23653, saving model to model.weights.kernel1.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.2776 - accuracy: 0.8965 - val_loss: 0.2365 - val_accuracy: 0.9134\n",
            "Epoch 7/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2678 - accuracy: 0.9007\n",
            "Epoch 7: val_loss improved from 0.23653 to 0.22721, saving model to model.weights.kernel1.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2679 - accuracy: 0.9007 - val_loss: 0.2272 - val_accuracy: 0.9154\n",
            "Epoch 8/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2560 - accuracy: 0.9042\n",
            "Epoch 8: val_loss improved from 0.22721 to 0.21870, saving model to model.weights.kernel1.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2560 - accuracy: 0.9042 - val_loss: 0.2187 - val_accuracy: 0.9180\n",
            "Epoch 9/10\n",
            "854/860 [============================>.] - ETA: 0s - loss: 0.2508 - accuracy: 0.9059\n",
            "Epoch 9: val_loss did not improve from 0.21870\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.2511 - accuracy: 0.9059 - val_loss: 0.2212 - val_accuracy: 0.9210\n",
            "Epoch 10/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2429 - accuracy: 0.9097\n",
            "Epoch 10: val_loss improved from 0.21870 to 0.21137, saving model to model.weights.kernel1.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.2428 - accuracy: 0.9097 - val_loss: 0.2114 - val_accuracy: 0.9228\n",
            "\n",
            " Test accuracy: 0.9135000109672546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.kernel2.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=10,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])\n",
        "\n",
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.kernel2.hdf5')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiyAPFiGADHP",
        "outputId": "36867bd6-8f1a-4a8a-92ee-a7e47f654446"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 14, 14, 32)        8224      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 7, 7, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 7, 7, 32)          0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               401664    \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 413,098\n",
            "Trainable params: 413,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.5903 - accuracy: 0.7827\n",
            "Epoch 1: val_loss improved from inf to 0.35918, saving model to model.weights.kernel2.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.5903 - accuracy: 0.7827 - val_loss: 0.3592 - val_accuracy: 0.8760\n",
            "Epoch 2/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.4056 - accuracy: 0.8527\n",
            "Epoch 2: val_loss improved from 0.35918 to 0.31017, saving model to model.weights.kernel2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.4056 - accuracy: 0.8527 - val_loss: 0.3102 - val_accuracy: 0.8910\n",
            "Epoch 3/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.3576 - accuracy: 0.8689\n",
            "Epoch 3: val_loss improved from 0.31017 to 0.29037, saving model to model.weights.kernel2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3577 - accuracy: 0.8689 - val_loss: 0.2904 - val_accuracy: 0.8936\n",
            "Epoch 4/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.3311 - accuracy: 0.8780\n",
            "Epoch 4: val_loss improved from 0.29037 to 0.26948, saving model to model.weights.kernel2.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3311 - accuracy: 0.8780 - val_loss: 0.2695 - val_accuracy: 0.8982\n",
            "Epoch 5/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.3153 - accuracy: 0.8842\n",
            "Epoch 5: val_loss improved from 0.26948 to 0.24861, saving model to model.weights.kernel2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3151 - accuracy: 0.8843 - val_loss: 0.2486 - val_accuracy: 0.9046\n",
            "Epoch 6/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.8902\n",
            "Epoch 6: val_loss improved from 0.24861 to 0.24680, saving model to model.weights.kernel2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3008 - accuracy: 0.8902 - val_loss: 0.2468 - val_accuracy: 0.9094\n",
            "Epoch 7/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.2863 - accuracy: 0.8940\n",
            "Epoch 7: val_loss improved from 0.24680 to 0.23397, saving model to model.weights.kernel2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2863 - accuracy: 0.8939 - val_loss: 0.2340 - val_accuracy: 0.9096\n",
            "Epoch 8/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.2767 - accuracy: 0.8968\n",
            "Epoch 8: val_loss improved from 0.23397 to 0.22039, saving model to model.weights.kernel2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2764 - accuracy: 0.8970 - val_loss: 0.2204 - val_accuracy: 0.9188\n",
            "Epoch 9/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2684 - accuracy: 0.8997\n",
            "Epoch 9: val_loss did not improve from 0.22039\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2683 - accuracy: 0.8997 - val_loss: 0.2207 - val_accuracy: 0.9144\n",
            "Epoch 10/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.9050\n",
            "Epoch 10: val_loss improved from 0.22039 to 0.21486, saving model to model.weights.kernel2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2555 - accuracy: 0.9050 - val_loss: 0.2149 - val_accuracy: 0.9200\n",
            "\n",
            " Test accuracy: 0.9111999869346619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.dropout1.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=10,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])\n",
        "\n",
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.dropout1.hdf5')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3je5StjIAt6y",
        "outputId": "d804eaef-04d6-4714-d0f6-0b884410c672"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_14 (Conv2D)          (None, 28, 28, 64)        320       \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 14, 14, 32)        8224      \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 7, 7, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 7, 7, 32)          0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 256)               401664    \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 412,778\n",
            "Trainable params: 412,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.5918 - accuracy: 0.7821\n",
            "Epoch 1: val_loss improved from inf to 0.36805, saving model to model.weights.dropout1.hdf5\n",
            "860/860 [==============================] - 10s 10ms/step - loss: 0.5909 - accuracy: 0.7823 - val_loss: 0.3681 - val_accuracy: 0.8706\n",
            "Epoch 2/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.4028 - accuracy: 0.8548\n",
            "Epoch 2: val_loss improved from 0.36805 to 0.31485, saving model to model.weights.dropout1.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.4030 - accuracy: 0.8547 - val_loss: 0.3149 - val_accuracy: 0.8876\n",
            "Epoch 3/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.3588 - accuracy: 0.8688\n",
            "Epoch 3: val_loss did not improve from 0.31485\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3587 - accuracy: 0.8689 - val_loss: 0.3203 - val_accuracy: 0.8800\n",
            "Epoch 4/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.3345 - accuracy: 0.8761\n",
            "Epoch 4: val_loss improved from 0.31485 to 0.27258, saving model to model.weights.dropout1.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3345 - accuracy: 0.8761 - val_loss: 0.2726 - val_accuracy: 0.9000\n",
            "Epoch 5/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.3132 - accuracy: 0.8844\n",
            "Epoch 5: val_loss improved from 0.27258 to 0.25844, saving model to model.weights.dropout1.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3134 - accuracy: 0.8844 - val_loss: 0.2584 - val_accuracy: 0.9016\n",
            "Epoch 6/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.2986 - accuracy: 0.8901\n",
            "Epoch 6: val_loss improved from 0.25844 to 0.25240, saving model to model.weights.dropout1.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.2987 - accuracy: 0.8901 - val_loss: 0.2524 - val_accuracy: 0.9066\n",
            "Epoch 7/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2840 - accuracy: 0.8944\n",
            "Epoch 7: val_loss improved from 0.25240 to 0.23978, saving model to model.weights.dropout1.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2840 - accuracy: 0.8944 - val_loss: 0.2398 - val_accuracy: 0.9116\n",
            "Epoch 8/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2733 - accuracy: 0.8982\n",
            "Epoch 8: val_loss improved from 0.23978 to 0.22928, saving model to model.weights.dropout1.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2734 - accuracy: 0.8981 - val_loss: 0.2293 - val_accuracy: 0.9130\n",
            "Epoch 9/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.2652 - accuracy: 0.9032\n",
            "Epoch 9: val_loss improved from 0.22928 to 0.22410, saving model to model.weights.dropout1.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.2656 - accuracy: 0.9030 - val_loss: 0.2241 - val_accuracy: 0.9172\n",
            "Epoch 10/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.2584 - accuracy: 0.9042\n",
            "Epoch 10: val_loss did not improve from 0.22410\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2584 - accuracy: 0.9043 - val_loss: 0.2321 - val_accuracy: 0.9130\n",
            "\n",
            " Test accuracy: 0.911300003528595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.dropout2.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=10,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])\n",
        "\n",
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.dropout2.hdf5')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cigm0sYwBmwe",
        "outputId": "73f190e7-bb1c-4e81-e876-68477ba3c5c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 28, 28, 64)        320       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 14, 14, 32)        8224      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 7, 7, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 7, 7, 32)          0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 256)               401664    \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 412,778\n",
            "Trainable params: 412,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.5959 - accuracy: 0.7804\n",
            "Epoch 1: val_loss improved from inf to 0.37410, saving model to model.weights.dropout2.hdf5\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.5959 - accuracy: 0.7804 - val_loss: 0.3741 - val_accuracy: 0.8646\n",
            "Epoch 2/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.4078 - accuracy: 0.8508\n",
            "Epoch 2: val_loss improved from 0.37410 to 0.31954, saving model to model.weights.dropout2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.4080 - accuracy: 0.8507 - val_loss: 0.3195 - val_accuracy: 0.8862\n",
            "Epoch 3/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.3629 - accuracy: 0.8679\n",
            "Epoch 3: val_loss improved from 0.31954 to 0.29437, saving model to model.weights.dropout2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3628 - accuracy: 0.8680 - val_loss: 0.2944 - val_accuracy: 0.8958\n",
            "Epoch 4/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.3339 - accuracy: 0.8776\n",
            "Epoch 4: val_loss improved from 0.29437 to 0.27329, saving model to model.weights.dropout2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3340 - accuracy: 0.8777 - val_loss: 0.2733 - val_accuracy: 0.9008\n",
            "Epoch 5/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.3137 - accuracy: 0.8847\n",
            "Epoch 5: val_loss did not improve from 0.27329\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3139 - accuracy: 0.8847 - val_loss: 0.2745 - val_accuracy: 0.8898\n",
            "Epoch 6/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.2978 - accuracy: 0.8909\n",
            "Epoch 6: val_loss improved from 0.27329 to 0.25282, saving model to model.weights.dropout2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2977 - accuracy: 0.8909 - val_loss: 0.2528 - val_accuracy: 0.9086\n",
            "Epoch 7/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.2843 - accuracy: 0.8961\n",
            "Epoch 7: val_loss improved from 0.25282 to 0.23399, saving model to model.weights.dropout2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2846 - accuracy: 0.8960 - val_loss: 0.2340 - val_accuracy: 0.9104\n",
            "Epoch 8/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.2748 - accuracy: 0.8983\n",
            "Epoch 8: val_loss did not improve from 0.23399\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2748 - accuracy: 0.8983 - val_loss: 0.2434 - val_accuracy: 0.9088\n",
            "Epoch 9/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.2654 - accuracy: 0.9030\n",
            "Epoch 9: val_loss did not improve from 0.23399\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2656 - accuracy: 0.9028 - val_loss: 0.2502 - val_accuracy: 0.9010\n",
            "Epoch 10/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2563 - accuracy: 0.9052\n",
            "Epoch 10: val_loss improved from 0.23399 to 0.21734, saving model to model.weights.dropout2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2561 - accuracy: 0.9053 - val_loss: 0.2173 - val_accuracy: 0.9188\n",
            "\n",
            " Test accuracy: 0.9106000065803528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu')) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.extralayer.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=10,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])\n",
        "\n",
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.extralayer.hdf5')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJMM6UNOCKRh",
        "outputId": "863bea45-e671-46f6-b01c-f4069a398a90"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 28, 28, 64)        320       \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 14, 14, 32)        8224      \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 7, 7, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 7, 7, 32)          0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 7, 7, 64)          8256      \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 3, 3, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 3, 3, 64)          0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 3, 3, 32)          8224      \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 1, 1, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 1, 1, 32)          0         \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 256)               8448      \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 36,042\n",
            "Trainable params: 36,042\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 1.0907 - accuracy: 0.5756\n",
            "Epoch 1: val_loss improved from inf to 0.64371, saving model to model.weights.extralayer.hdf5\n",
            "860/860 [==============================] - 11s 11ms/step - loss: 1.0907 - accuracy: 0.5756 - val_loss: 0.6437 - val_accuracy: 0.7386\n",
            "Epoch 2/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.7225 - accuracy: 0.7201\n",
            "Epoch 2: val_loss improved from 0.64371 to 0.53698, saving model to model.weights.extralayer.hdf5\n",
            "860/860 [==============================] - 9s 11ms/step - loss: 0.7225 - accuracy: 0.7201 - val_loss: 0.5370 - val_accuracy: 0.8044\n",
            "Epoch 3/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.6480 - accuracy: 0.7537\n",
            "Epoch 3: val_loss improved from 0.53698 to 0.46208, saving model to model.weights.extralayer.hdf5\n",
            "860/860 [==============================] - 9s 11ms/step - loss: 0.6475 - accuracy: 0.7540 - val_loss: 0.4621 - val_accuracy: 0.8288\n",
            "Epoch 4/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.5953 - accuracy: 0.7755\n",
            "Epoch 4: val_loss improved from 0.46208 to 0.42892, saving model to model.weights.extralayer.hdf5\n",
            "860/860 [==============================] - 9s 11ms/step - loss: 0.5952 - accuracy: 0.7755 - val_loss: 0.4289 - val_accuracy: 0.8420\n",
            "Epoch 5/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.5617 - accuracy: 0.7908\n",
            "Epoch 5: val_loss improved from 0.42892 to 0.42033, saving model to model.weights.extralayer.hdf5\n",
            "860/860 [==============================] - 9s 11ms/step - loss: 0.5614 - accuracy: 0.7910 - val_loss: 0.4203 - val_accuracy: 0.8512\n",
            "Epoch 6/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.5388 - accuracy: 0.8020\n",
            "Epoch 6: val_loss improved from 0.42033 to 0.39005, saving model to model.weights.extralayer.hdf5\n",
            "860/860 [==============================] - 9s 11ms/step - loss: 0.5388 - accuracy: 0.8019 - val_loss: 0.3900 - val_accuracy: 0.8594\n",
            "Epoch 7/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.5193 - accuracy: 0.8123\n",
            "Epoch 7: val_loss improved from 0.39005 to 0.37993, saving model to model.weights.extralayer.hdf5\n",
            "860/860 [==============================] - 9s 11ms/step - loss: 0.5193 - accuracy: 0.8123 - val_loss: 0.3799 - val_accuracy: 0.8680\n",
            "Epoch 8/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.4978 - accuracy: 0.8206\n",
            "Epoch 8: val_loss improved from 0.37993 to 0.36234, saving model to model.weights.extralayer.hdf5\n",
            "860/860 [==============================] - 9s 11ms/step - loss: 0.4976 - accuracy: 0.8207 - val_loss: 0.3623 - val_accuracy: 0.8682\n",
            "Epoch 9/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.4852 - accuracy: 0.8218\n",
            "Epoch 9: val_loss improved from 0.36234 to 0.36066, saving model to model.weights.extralayer.hdf5\n",
            "860/860 [==============================] - 9s 11ms/step - loss: 0.4853 - accuracy: 0.8217 - val_loss: 0.3607 - val_accuracy: 0.8732\n",
            "Epoch 10/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.4747 - accuracy: 0.8291\n",
            "Epoch 10: val_loss improved from 0.36066 to 0.35814, saving model to model.weights.extralayer.hdf5\n",
            "860/860 [==============================] - 9s 11ms/step - loss: 0.4746 - accuracy: 0.8291 - val_loss: 0.3581 - val_accuracy: 0.8706\n",
            "\n",
            " Test accuracy: 0.8632000088691711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.arch1.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=10,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])\n",
        "\n",
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.arch1.hdf5')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6cXRF9pFjHW",
        "outputId": "fc82911d-7875-489a-c11e-6e34165d6adf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 28, 28, 32)        160       \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 14, 14, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 14, 14, 16)        2064      \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 7, 7, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 7, 7, 16)          0         \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 205,754\n",
            "Trainable params: 205,754\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.6774 - accuracy: 0.7483\n",
            "Epoch 1: val_loss improved from inf to 0.42726, saving model to model.weights.arch1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.6774 - accuracy: 0.7483 - val_loss: 0.4273 - val_accuracy: 0.8490\n",
            "Epoch 2/10\n",
            "853/860 [============================>.] - ETA: 0s - loss: 0.4737 - accuracy: 0.8255\n",
            "Epoch 2: val_loss improved from 0.42726 to 0.36818, saving model to model.weights.arch1.hdf5\n",
            "860/860 [==============================] - 6s 8ms/step - loss: 0.4732 - accuracy: 0.8258 - val_loss: 0.3682 - val_accuracy: 0.8702\n",
            "Epoch 3/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.4268 - accuracy: 0.8439\n",
            "Epoch 3: val_loss improved from 0.36818 to 0.33237, saving model to model.weights.arch1.hdf5\n",
            "860/860 [==============================] - 6s 8ms/step - loss: 0.4269 - accuracy: 0.8439 - val_loss: 0.3324 - val_accuracy: 0.8832\n",
            "Epoch 4/10\n",
            "853/860 [============================>.] - ETA: 0s - loss: 0.4014 - accuracy: 0.8520\n",
            "Epoch 4: val_loss improved from 0.33237 to 0.31683, saving model to model.weights.arch1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.4011 - accuracy: 0.8523 - val_loss: 0.3168 - val_accuracy: 0.8890\n",
            "Epoch 5/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8605\n",
            "Epoch 5: val_loss improved from 0.31683 to 0.30235, saving model to model.weights.arch1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3778 - accuracy: 0.8605 - val_loss: 0.3024 - val_accuracy: 0.8900\n",
            "Epoch 6/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.3641 - accuracy: 0.8666\n",
            "Epoch 6: val_loss improved from 0.30235 to 0.29235, saving model to model.weights.arch1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3642 - accuracy: 0.8665 - val_loss: 0.2923 - val_accuracy: 0.8928\n",
            "Epoch 7/10\n",
            "854/860 [============================>.] - ETA: 0s - loss: 0.3545 - accuracy: 0.8707\n",
            "Epoch 7: val_loss improved from 0.29235 to 0.28486, saving model to model.weights.arch1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3539 - accuracy: 0.8709 - val_loss: 0.2849 - val_accuracy: 0.8936\n",
            "Epoch 8/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.3412 - accuracy: 0.8753\n",
            "Epoch 8: val_loss improved from 0.28486 to 0.28221, saving model to model.weights.arch1.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3409 - accuracy: 0.8754 - val_loss: 0.2822 - val_accuracy: 0.8964\n",
            "Epoch 9/10\n",
            "854/860 [============================>.] - ETA: 0s - loss: 0.3318 - accuracy: 0.8765\n",
            "Epoch 9: val_loss improved from 0.28221 to 0.26983, saving model to model.weights.arch1.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3321 - accuracy: 0.8765 - val_loss: 0.2698 - val_accuracy: 0.9020\n",
            "Epoch 10/10\n",
            "854/860 [============================>.] - ETA: 0s - loss: 0.3260 - accuracy: 0.8786\n",
            "Epoch 10: val_loss did not improve from 0.26983\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3261 - accuracy: 0.8785 - val_loss: 0.2709 - val_accuracy: 0.8986\n",
            "\n",
            " Test accuracy: 0.8955000042915344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=5, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=5, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.arch2.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=10,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])\n",
        "\n",
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.arch2.hdf5')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5raBMT5Gf2O",
        "outputId": "1bb2285d-d28a-4012-8a4e-12481c0bbbee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 28, 28, 32)        832       \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 14, 14, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 14, 14, 16)        12816     \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 7, 7, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 7, 7, 16)          0         \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 217,178\n",
            "Trainable params: 217,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.5853 - accuracy: 0.7852\n",
            "Epoch 1: val_loss improved from inf to 0.34548, saving model to model.weights.arch2.hdf5\n",
            "860/860 [==============================] - 9s 9ms/step - loss: 0.5853 - accuracy: 0.7852 - val_loss: 0.3455 - val_accuracy: 0.8764\n",
            "Epoch 2/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8593\n",
            "Epoch 2: val_loss improved from 0.34548 to 0.30089, saving model to model.weights.arch2.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3865 - accuracy: 0.8593 - val_loss: 0.3009 - val_accuracy: 0.8922\n",
            "Epoch 3/10\n",
            "854/860 [============================>.] - ETA: 0s - loss: 0.3422 - accuracy: 0.8746\n",
            "Epoch 3: val_loss improved from 0.30089 to 0.27528, saving model to model.weights.arch2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3419 - accuracy: 0.8746 - val_loss: 0.2753 - val_accuracy: 0.8980\n",
            "Epoch 4/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.3138 - accuracy: 0.8849\n",
            "Epoch 4: val_loss improved from 0.27528 to 0.26089, saving model to model.weights.arch2.hdf5\n",
            "860/860 [==============================] - 7s 8ms/step - loss: 0.3138 - accuracy: 0.8849 - val_loss: 0.2609 - val_accuracy: 0.9010\n",
            "Epoch 5/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.8902\n",
            "Epoch 5: val_loss improved from 0.26089 to 0.24943, saving model to model.weights.arch2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2977 - accuracy: 0.8901 - val_loss: 0.2494 - val_accuracy: 0.9098\n",
            "Epoch 6/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.2806 - accuracy: 0.8957\n",
            "Epoch 6: val_loss improved from 0.24943 to 0.23849, saving model to model.weights.arch2.hdf5\n",
            "860/860 [==============================] - 7s 9ms/step - loss: 0.2805 - accuracy: 0.8958 - val_loss: 0.2385 - val_accuracy: 0.9100\n",
            "Epoch 7/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.9000\n",
            "Epoch 7: val_loss improved from 0.23849 to 0.23051, saving model to model.weights.arch2.hdf5\n",
            "860/860 [==============================] - 7s 9ms/step - loss: 0.2709 - accuracy: 0.9000 - val_loss: 0.2305 - val_accuracy: 0.9138\n",
            "Epoch 8/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2620 - accuracy: 0.9036\n",
            "Epoch 8: val_loss did not improve from 0.23051\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.2619 - accuracy: 0.9036 - val_loss: 0.2336 - val_accuracy: 0.9120\n",
            "Epoch 9/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.2537 - accuracy: 0.9059\n",
            "Epoch 9: val_loss improved from 0.23051 to 0.22788, saving model to model.weights.arch2.hdf5\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.2538 - accuracy: 0.9058 - val_loss: 0.2279 - val_accuracy: 0.9140\n",
            "Epoch 10/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2456 - accuracy: 0.9088\n",
            "Epoch 10: val_loss improved from 0.22788 to 0.21705, saving model to model.weights.arch2.hdf5\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.2457 - accuracy: 0.9087 - val_loss: 0.2170 - val_accuracy: 0.9172\n",
            "\n",
            " Test accuracy: 0.9107999801635742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.arch3.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=10,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])\n",
        "\n",
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.arch3.hdf5')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neeQe-W4HkyU",
        "outputId": "50ee5157-e388-43bb-afd6-a41db7b0fd69"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_28 (Conv2D)          (None, 28, 28, 128)       640       \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 14, 14, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 14, 14, 64)        32832     \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 256)               803072    \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 839,114\n",
            "Trainable params: 839,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.5610 - accuracy: 0.7950\n",
            "Epoch 1: val_loss improved from inf to 0.34455, saving model to model.weights.arch3.hdf5\n",
            "860/860 [==============================] - 13s 14ms/step - loss: 0.5610 - accuracy: 0.7950 - val_loss: 0.3445 - val_accuracy: 0.8792\n",
            "Epoch 2/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8618\n",
            "Epoch 2: val_loss improved from 0.34455 to 0.29365, saving model to model.weights.arch3.hdf5\n",
            "860/860 [==============================] - 12s 14ms/step - loss: 0.3831 - accuracy: 0.8619 - val_loss: 0.2937 - val_accuracy: 0.8940\n",
            "Epoch 3/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.3410 - accuracy: 0.8759\n",
            "Epoch 3: val_loss improved from 0.29365 to 0.27801, saving model to model.weights.arch3.hdf5\n",
            "860/860 [==============================] - 12s 14ms/step - loss: 0.3409 - accuracy: 0.8759 - val_loss: 0.2780 - val_accuracy: 0.8982\n",
            "Epoch 4/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.3125 - accuracy: 0.8836\n",
            "Epoch 4: val_loss improved from 0.27801 to 0.25724, saving model to model.weights.arch3.hdf5\n",
            "860/860 [==============================] - 12s 14ms/step - loss: 0.3127 - accuracy: 0.8834 - val_loss: 0.2572 - val_accuracy: 0.9018\n",
            "Epoch 5/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.2926 - accuracy: 0.8925\n",
            "Epoch 5: val_loss improved from 0.25724 to 0.24414, saving model to model.weights.arch3.hdf5\n",
            "860/860 [==============================] - 12s 14ms/step - loss: 0.2926 - accuracy: 0.8926 - val_loss: 0.2441 - val_accuracy: 0.9104\n",
            "Epoch 6/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.2760 - accuracy: 0.8981\n",
            "Epoch 6: val_loss improved from 0.24414 to 0.23122, saving model to model.weights.arch3.hdf5\n",
            "860/860 [==============================] - 12s 14ms/step - loss: 0.2759 - accuracy: 0.8981 - val_loss: 0.2312 - val_accuracy: 0.9162\n",
            "Epoch 7/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.2605 - accuracy: 0.9044\n",
            "Epoch 7: val_loss did not improve from 0.23122\n",
            "860/860 [==============================] - 12s 14ms/step - loss: 0.2605 - accuracy: 0.9044 - val_loss: 0.2383 - val_accuracy: 0.9092\n",
            "Epoch 8/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.2505 - accuracy: 0.9076\n",
            "Epoch 8: val_loss improved from 0.23122 to 0.21512, saving model to model.weights.arch3.hdf5\n",
            "860/860 [==============================] - 12s 14ms/step - loss: 0.2507 - accuracy: 0.9075 - val_loss: 0.2151 - val_accuracy: 0.9188\n",
            "Epoch 9/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.2404 - accuracy: 0.9126\n",
            "Epoch 9: val_loss did not improve from 0.21512\n",
            "860/860 [==============================] - 12s 14ms/step - loss: 0.2405 - accuracy: 0.9125 - val_loss: 0.2298 - val_accuracy: 0.9148\n",
            "Epoch 10/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.9145\n",
            "Epoch 10: val_loss did not improve from 0.21512\n",
            "860/860 [==============================] - 12s 14ms/step - loss: 0.2326 - accuracy: 0.9145 - val_loss: 0.2164 - val_accuracy: 0.9160\n",
            "\n",
            " Test accuracy: 0.9128000140190125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=3))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=3))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.arch4.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=10,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])\n",
        "\n",
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.arch4.hdf5')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTKvzDd5Ilze",
        "outputId": "fee86351-56ce-47ae-d421-c4eb4d068889"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_32 (Conv2D)          (None, 28, 28, 128)       1280      \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 9, 9, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 9, 9, 128)         0         \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 9, 9, 64)          73792     \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (None, 3, 3, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 3, 3, 64)          0         \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 576)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 256)               147712    \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225,354\n",
            "Trainable params: 225,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.6525 - accuracy: 0.7596\n",
            "Epoch 1: val_loss improved from inf to 0.36971, saving model to model.weights.arch4.hdf5\n",
            "860/860 [==============================] - 12s 13ms/step - loss: 0.6520 - accuracy: 0.7597 - val_loss: 0.3697 - val_accuracy: 0.8678\n",
            "Epoch 2/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.4141 - accuracy: 0.8502\n",
            "Epoch 2: val_loss improved from 0.36971 to 0.30779, saving model to model.weights.arch4.hdf5\n",
            "860/860 [==============================] - 10s 12ms/step - loss: 0.4140 - accuracy: 0.8502 - val_loss: 0.3078 - val_accuracy: 0.8942\n",
            "Epoch 3/10\n",
            "860/860 [==============================] - ETA: 0s - loss: 0.3640 - accuracy: 0.8671\n",
            "Epoch 3: val_loss improved from 0.30779 to 0.28081, saving model to model.weights.arch4.hdf5\n",
            "860/860 [==============================] - 10s 12ms/step - loss: 0.3640 - accuracy: 0.8671 - val_loss: 0.2808 - val_accuracy: 0.8958\n",
            "Epoch 4/10\n",
            "857/860 [============================>.] - ETA: 0s - loss: 0.3379 - accuracy: 0.8746\n",
            "Epoch 4: val_loss improved from 0.28081 to 0.26876, saving model to model.weights.arch4.hdf5\n",
            "860/860 [==============================] - 10s 12ms/step - loss: 0.3377 - accuracy: 0.8747 - val_loss: 0.2688 - val_accuracy: 0.9020\n",
            "Epoch 5/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.3147 - accuracy: 0.8832\n",
            "Epoch 5: val_loss improved from 0.26876 to 0.25383, saving model to model.weights.arch4.hdf5\n",
            "860/860 [==============================] - 10s 12ms/step - loss: 0.3147 - accuracy: 0.8832 - val_loss: 0.2538 - val_accuracy: 0.9046\n",
            "Epoch 6/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.3009 - accuracy: 0.8889\n",
            "Epoch 6: val_loss improved from 0.25383 to 0.24602, saving model to model.weights.arch4.hdf5\n",
            "860/860 [==============================] - 10s 12ms/step - loss: 0.3010 - accuracy: 0.8888 - val_loss: 0.2460 - val_accuracy: 0.9124\n",
            "Epoch 7/10\n",
            "859/860 [============================>.] - ETA: 0s - loss: 0.2879 - accuracy: 0.8925\n",
            "Epoch 7: val_loss improved from 0.24602 to 0.24027, saving model to model.weights.arch4.hdf5\n",
            "860/860 [==============================] - 10s 12ms/step - loss: 0.2878 - accuracy: 0.8925 - val_loss: 0.2403 - val_accuracy: 0.9156\n",
            "Epoch 8/10\n",
            "858/860 [============================>.] - ETA: 0s - loss: 0.2829 - accuracy: 0.8945\n",
            "Epoch 8: val_loss improved from 0.24027 to 0.22991, saving model to model.weights.arch4.hdf5\n",
            "860/860 [==============================] - 10s 12ms/step - loss: 0.2829 - accuracy: 0.8946 - val_loss: 0.2299 - val_accuracy: 0.9148\n",
            "Epoch 9/10\n",
            "855/860 [============================>.] - ETA: 0s - loss: 0.2751 - accuracy: 0.8987\n",
            "Epoch 9: val_loss did not improve from 0.22991\n",
            "860/860 [==============================] - 10s 12ms/step - loss: 0.2750 - accuracy: 0.8987 - val_loss: 0.2307 - val_accuracy: 0.9186\n",
            "Epoch 10/10\n",
            "856/860 [============================>.] - ETA: 0s - loss: 0.2638 - accuracy: 0.9024\n",
            "Epoch 10: val_loss did not improve from 0.22991\n",
            "860/860 [==============================] - 10s 12ms/step - loss: 0.2639 - accuracy: 0.9024 - val_loss: 0.2475 - val_accuracy: 0.9030\n",
            "\n",
            " Test accuracy: 0.9067999720573425\n"
          ]
        }
      ]
    }
  ]
}